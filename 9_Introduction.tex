%!TEX root = optimization1718.tex

\chapter{Introduction}

This term we plan to cover the following material.

\subsubsection*{Online Optimization (week 2 and week 3)}
Prediction with expert advice. Follow the perturbed leader. Stochastic bandits.\\
Lecture 15, 16 and 18 in \cite{rigollet}. See also relevant material in \cite{barlett08}.

\subsubsection*{Support Vector Machines and Kernels (week 3 and week 4)}
Reproducing Kernel Hilbert Spaces, Support Vector Machines. Generalization bounds for for SVM using Rademacher complexity.\\
Lecture 9 (Support Vector Machines), Lecture 10, Lecture 12 (only Example 2.3.3) in \cite{rigollet}. See also relevant material in \cite{barlett08}.

\subsubsection*{Adaboost (week 5, week 6, week 7)}
AdaBoost and universal consistency.\\
Lecture 17, 18, 19 in \cite{barlett16}.\\

\noindent Kernel boosting algorithm. Generalization bounds via early stopping.\\
Paper \cite{wain17ada}.

\subsubsection*{Robust Optimization (week 8, possibly also later)}
Robust empirical risk minimization. Generalization bounds using localized Rademacher complexities.\\
Paper \cite{duchi17roubust}.

\subsubsection*{Neural Networks (moving forward)}
Generalization bounds for Neural Networks using margin theory.\\
Paper \cite{DBLP:journals/corr/BartlettFT17}.